{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd M:/Rafael/Documentos/GitHub/TCC\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from vector import recupera_arquivos_token\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carrega_dados(filtro=None):\n",
    "    ''' Importa arquivos dos dados dos artigos ''' \n",
    "    dados = {}\n",
    "    lista_arquivos_entrada = recupera_arquivos_token(filtro=filtro) \n",
    "    for nome_arquivo in lista_arquivos_entrada:\n",
    "        caminho = 'data/dataset_final/'\n",
    "        hora = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        print(f'({hora}) Processando arquivo {nome_arquivo} ... ', end='')\n",
    "        with open(caminho + nome_arquivo, 'r', encoding = 'utf-8') as arquivo_json:\n",
    "            artigos = json.load(arquivo_json)\n",
    "            nome_portal = nome_arquivo[2:-5].split('-')[0]\n",
    "            if not nome_portal in dados:\n",
    "                dados[nome_portal] = artigos\n",
    "                #print('\\ncriando', len(artigos))\n",
    "            else:\n",
    "                dados[nome_portal].extend(artigos)\n",
    "            print(f'{len(artigos)} artigos carregados ')\n",
    "    return dados, filtro or 'Todos'\n",
    "\n",
    "#dados_e = carrega_dados('E')    \n",
    "#dados_d = carrega_dados('D')    \n",
    "#dados_i = carrega_dados('I') \n",
    "\n",
    "#'247'\n",
    "#'dcm'\n",
    "#'conexaopolitica'\n",
    "#'tercalivre'\n",
    "#'senso'\n",
    "#'republica'\n",
    "\n",
    "\n",
    "dados, portal = carrega_dados()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total de registros\n",
    "len_total = 0 \n",
    "for dado in dados:\n",
    "    print(dado, '\\t' * round((3 - len(dado)/5)), len(dados[dado]))\n",
    "    len_total += len(dados[dado])\n",
    "print(f'TOTAL\\t\\t {len_total}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plota_duplicados(portal):\n",
    "    ''' Representação em gráfico de torta ou pizza da quantidade de valores duplucados para um determinado portal '''\n",
    "    df = pd.DataFrame(dados[portal])\n",
    "    perc_duplicados = round((df.duplicated().value_counts()[1] / df.duplicated().count()) * 100, 1)\n",
    "    \n",
    "    df.duplicated().value_counts().plot.pie(title=f'Portal: {portal}', ylabel='', \n",
    "                                            labels=['',f'duplicados {perc_duplicados}%'])\n",
    "    \n",
    "    plt.savefig(\"dup_\" + portal +\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plota_duplicados('conexaopolitica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plota_duplicados('republica')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plota_duplicados('senso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plota_duplicados('tercalivre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plota_duplicados('247')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plota_duplicados('dcm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levantamento de informações de armazenamento do dataframe (Memória/Min/Max)\n",
    "\n",
    "df_info = pd.DataFrame(columns=['Portal', 'Memória (GB)', 'Documentos', 'Palavras', '(min)', '(max)'])\n",
    "df_info = df_info.astype({'Portal':str, 'Memória (GB)':float, 'Documentos':int, 'Palavras':int, '(min)':int, '(max)':int })      \n",
    "\n",
    "GB = 1000 * 1000 * 1000\n",
    "for portal in dados:\n",
    "    df = pd.DataFrame(dados[portal])\n",
    "    tamanho_df = round(df.memory_usage().sum() / GB, 2)\n",
    "    n_palavras = 0\n",
    "    min_palavras = 99999\n",
    "    max_palavras = 0\n",
    "    for documento in dados[portal]:\n",
    "        n_palavras += len(documento)\n",
    "        if len(documento) < min_palavras:\n",
    "            min_palavras = len(documento)\n",
    "        if len(documento) > max_palavras:\n",
    "            max_palavras = len(documento)    \n",
    "    info = [{'Portal':portal, 'Memória (GB)':tamanho_df,  'Documentos':len(dados[portal]), \n",
    "             'Palavras':n_palavras, '(min)':min_palavras, '(max)':max_palavras}]\n",
    "    df_info = df_info.append(info, ignore_index=True)\n",
    "    print(portal, '- Memória ocupada:', str(tamanho_df), 'GB', min_palavras, max_palavras)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info.round(2).loc[: , ['Memória (GB)', 'Documentos' , 'Palavras']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando outliers\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1)\n",
    "\n",
    "len(dados)\n",
    "lista_wordcount = []\n",
    "for dado in dados:\n",
    "    artigos = dados[dado]\n",
    "    for artigo in artigos:\n",
    "        lista_wordcount.append(len(artigo))\n",
    "\n",
    "serie = pd.Series(lista_wordcount)\n",
    "\n",
    "df_describe = pd.DataFrame(columns=serie.describe().index)\n",
    "df_describe = df_describe.append(serie.describe(), ignore_index=True)\n",
    "df_describe.columns = ['Nº Registros', 'Média', 'Desvio padrão', 'Min',\n",
    "                       '25%', '50%', '75%', 'Max']\n",
    "\n",
    "serie.plot.hist( figsize=(14,4),  title='Contagem de palavras x documentos' , bins=300)\n",
    "axes.set_xlabel('nº palavras')\n",
    "axes.set_ylabel('documentos')\n",
    "\n",
    "df_describe.style.hide_index().format('{:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie.plot.box(showfliers=False ,  title='Boxplot contagem de palavras') \n",
    "axes.set_ylabel('nº palavras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontra uma linha de corte - Calcula o Escore Z e busca o maior valor da série, onde z < 3.5\n",
    "from scipy import stats\n",
    "\n",
    "z = np.abs(stats.zscore(serie))\n",
    "n_corte = serie[np.where(z < 3.5)[0]].max()\n",
    "print(f'n_corte ({n_corte})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar DF (COM SLICING) sem importar denovo os arquivos (pegando o q ta na memoria)\n",
    "import pandas as pd\n",
    "\n",
    "df = None\n",
    "for dado in dados:\n",
    "    print(f'Carregando {dado} ...')\n",
    "    artigos = dados[dado]\n",
    "    tam = len(artigos)\n",
    "    \n",
    "    df_temp = pd.DataFrame(artigos).iloc[:, :n_corte]\n",
    "    \n",
    "    df_temp['portal'] = dado\n",
    "    if df is None:\n",
    "        df = df_temp\n",
    "    else:        \n",
    "        df = df_temp.append(df, ignore_index=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista a quantidade de documentos agrupados por Site, antes da remoção dos duplicados\n",
    "df.groupby(df['portal']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove registros duplicados\n",
    "df.drop_duplicates(ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista a quantidade de documentos agrupados por Site, após a remoção dos duplicados\n",
    "df.groupby(df['portal']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_1 = df.groupby(df['portal']).size().plot.bar(xlabel = 'Portais' ,ylabel='Nº documentos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[((df.portal=='247') | (df.portal=='dcm'), 'posicao')] = 'Esquerda'\n",
    "df.loc[(~(df.portal=='247') & ~(df.portal=='dcm'), 'posicao')] = 'Direita'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(df['posicao']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuvem de palavras\n",
    "def carrega_dados_wordcloud_portal(df, portal=None):\n",
    "    texto = df.loc[df['portal']==portal].drop(axis=1,labels=['portal', 'posicao']).fillna(value=np.nan).to_string(header=False, index=False, na_rep=\"\")\n",
    "    return texto\n",
    "\n",
    "\n",
    "# Define a função plotar nuvem de palavras\n",
    "def plot_cloud(wordcloud, titulo):\n",
    "    # Define tamanho\n",
    "    plt.figure(figsize=(40, 30))\n",
    "    # Mostra imagem\n",
    "    plt.title(f'wordcloud: \\'{titulo}\\'')\n",
    "    plt.imshow(wordcloud) \n",
    "    # Sem detalhes de axis\n",
    "    plt.axis(\"off\");\n",
    "    plt.savefig(f'nuvem_{titulo}.png')\n",
    "    \n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "texto = \"\"\n",
    "texto_esq = \"\"\n",
    "texto_dir = \"\"\n",
    "for p in df['portal'].unique():\n",
    "    print(f'Gerando nuvem de palavras para \\'{p}\\' ...')    \n",
    "    texto = carrega_dados_wordcloud_portal(df, portal=p)\n",
    "\n",
    "    if p == '247' or p == 'dcm':\n",
    "        texto_esq += texto\n",
    "    else:\n",
    "        texto_dir += texto\n",
    "        \n",
    "    # Gera Nuvem de Palavras\n",
    "    wordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='white', \n",
    "                          colormap='bone', normalize_plurals=False, regexp=r'[\\w\\-]+').generate(texto)\n",
    "\n",
    "    # Plota as imagens\n",
    "    plot_cloud(wordcloud, p)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 'direita'\n",
    "\n",
    "# Gera Nuvem de Palavras\n",
    "wordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='white', \n",
    "                      colormap='bone', normalize_plurals=False, regexp=r'[\\w\\-]+').generate(texto_dir)\n",
    "# Plot\n",
    "plot_cloud(wordcloud, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 'esquerda'\n",
    "\n",
    "# Gera Nuvem de Palavras\n",
    "wordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='white', \n",
    "                      colormap='bone', normalize_plurals=False, regexp=r'[\\w\\-]+').generate(texto_esq)\n",
    "# Plot\n",
    "plot_cloud(wordcloud, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 'Todos'\n",
    "\n",
    "# Gera Nuvem de Palavras\n",
    "wordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='white', \n",
    "                      colormap='bone', normalize_plurals=False, regexp=r'[\\w\\-]+').generate(texto_esq + \" \" + texto_dir)\n",
    "# Plot\n",
    "plot_cloud(wordcloud, p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_2 = df.groupby(df['posicao']).size().plot.bar(xlabel = 'Posição' ,ylabel='Nº documentos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contagem_palavras = df.drop(axis=1,labels=['portal', 'posicao']).stack().value_counts() \n",
    "len(contagem_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contagem_palavras.head(30).iloc[::-1].plot.barh(figsize=(8,14),  zorder=2, width=0.9);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset_final.csv', encoding='utf-8',sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
